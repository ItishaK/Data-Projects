{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "196c383d-3752-47d4-8056-8e3bd85cfb87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------------------+--------------------+\n",
      "| id|   name|           address|               email|\n",
      "+---+-------+------------------+--------------------+\n",
      "|  1|  Alice|   123 Main St, NY|alice.johnson@exa...|\n",
      "|  2|    Bob|  456 Park Ave, CA|bob.smith@example...|\n",
      "|  3|Charlie|    789 Oak St, TX|charlie.brown@exa...|\n",
      "|  4|  David|    321 Elm St, FL|david.williams@ex...|\n",
      "|  5|   Emma|   654 Pine St, WA|emma.davis@exampl...|\n",
      "|  6|  Frank|  987 Maple St, CO|frank.miller@exam...|\n",
      "|  7|  Grace|  246 Birch St, IL|grace.wilson@exam...|\n",
      "|  8| Hannah|  135 Cedar St, NV|hannah.moore@exam...|\n",
      "|  9|    Ian|  579 Aspen St, AZ|ian.taylor@exampl...|\n",
      "| 10|   Jack|864 Redwood St, NJ|jack.anderson@exa...|\n",
      "+---+-------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbc_url = \"jdbc:mysql://<your_server_name>.mysql.database.azure.com:3306/<your_database_name>\"\n",
    "connection_properties = {\n",
    "  \"user\": \"your_username\",\n",
    "  \"password\": \"your_password\",\n",
    "  \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "df_users = spark.read.jdbc(url=jdbc_url, table=\"<your_table_name>\", properties=connection_properties)\n",
    "df_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6516fa2-5c49-4e84-bac6-0c68bb2cb247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+--------------------+-------+\n",
      "| id|        name|         description|  price|\n",
      "+---+------------+--------------------+-------+\n",
      "|101|      Laptop|15-inch gaming la...|1200.00|\n",
      "|102|  Smartphone|Flagship 5G smart...| 999.00|\n",
      "|103|  Headphones|Noise-canceling w...| 250.00|\n",
      "|104|  Smartwatch|Waterproof fitnes...| 180.00|\n",
      "|105|      Tablet|10-inch Android t...| 350.00|\n",
      "|106|     Monitor|27-inch 4K UHD di...| 450.00|\n",
      "|107|    Keyboard|Mechanical RGB ga...| 120.00|\n",
      "|108|       Mouse|Wireless ergonomi...|  80.00|\n",
      "|109|     Printer|All-in-one color ...| 200.00|\n",
      "|110|External HDD|2TB portable hard...| 100.00|\n",
      "+---+------------+--------------------+-------+\n",
      "\n",
      "+----+-------+---------+----------+\n",
      "|  id|user_id|total_amt|order_date|\n",
      "+----+-------+---------+----------+\n",
      "|1001|      1|  1250.00|2024-01-01|\n",
      "|1002|      2|  1999.00|2024-01-02|\n",
      "|1003|      3|   250.00|2024-01-03|\n",
      "|1004|      4|   450.00|2024-01-04|\n",
      "|1005|      5|   180.00|2024-01-05|\n",
      "|1006|      6|   999.00|2024-01-06|\n",
      "|1007|      7|   350.00|2024-01-07|\n",
      "|1008|      8|   120.00|2024-01-08|\n",
      "|1009|      9|    80.00|2024-01-09|\n",
      "|1010|     10|   100.00|2024-01-10|\n",
      "+----+-------+---------+----------+\n",
      "\n",
      "+---+--------+----------+--------+-------+\n",
      "| id|order_id|product_id|quantity|  price|\n",
      "+---+--------+----------+--------+-------+\n",
      "|  1|    1001|       101|       1|1200.00|\n",
      "|  2|    1001|       103|       1|  50.00|\n",
      "|  3|    1002|       102|       2| 999.00|\n",
      "|  4|    1003|       103|       1| 250.00|\n",
      "|  5|    1004|       106|       1| 450.00|\n",
      "|  6|    1005|       104|       1| 180.00|\n",
      "|  7|    1006|       102|       1| 999.00|\n",
      "|  8|    1007|       105|       1| 350.00|\n",
      "|  9|    1008|       107|       1| 120.00|\n",
      "| 10|    1009|       108|       1|  80.00|\n",
      "+---+--------+----------+--------+-------+\n",
      "\n",
      "+---+-------+----------+-------------+-------------------+\n",
      "| id|user_id|product_id|activity_type|      activity_date|\n",
      "+---+-------+----------+-------------+-------------------+\n",
      "|  1|      1|       101|         view|2024-01-01 10:00:00|\n",
      "|  2|      1|       101|  add_to_cart|2024-01-01 10:05:00|\n",
      "|  3|      2|       102|         view|2024-01-02 12:00:00|\n",
      "|  4|      2|       102|     purchase|2024-01-02 12:10:00|\n",
      "|  5|      3|       103|         view|2024-01-03 14:00:00|\n",
      "|  6|      3|       103|  add_to_cart|2024-01-03 14:05:00|\n",
      "|  7|      4|       106|         view|2024-01-04 16:00:00|\n",
      "|  8|      5|       104|  add_to_cart|2024-01-05 18:00:00|\n",
      "|  9|      6|       102|         view|2024-01-06 20:00:00|\n",
      "| 10|      6|       102|     purchase|2024-01-06 20:05:00|\n",
      "+---+-------+----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_products = spark.read.jdbc(url=jdbc_url, table=\"products\", properties=connection_properties)\n",
    "df_orders = spark.read.jdbc(url=jdbc_url, table=\"orders\", properties=connection_properties)\n",
    "df_orderDetails = spark.read.jdbc(url=jdbc_url, table=\"orderDetails\", properties=connection_properties)\n",
    "df_userActivity = spark.read.jdbc(url=jdbc_url, table=\"userActivity\", properties=connection_properties)\n",
    "df_products.show()\n",
    "df_orders.show()\n",
    "df_orderDetails.show()\n",
    "df_userActivity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8072ecd-d8c9-413a-a6b3-ffde2ab4328f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_users.createOrReplaceTempView(\"users\")\n",
    "df_products.createOrReplaceTempView(\"products\")\n",
    "df_orders.createOrReplaceTempView(\"orders\")\n",
    "df_orderDetails.createOrReplaceTempView(\"orderDetails\")\n",
    "df_userActivity.createOrReplaceTempView(\"userActivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6671c941-2fcd-4670-a487-068955689dac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------------+\n",
      "|id |name   |email                    |\n",
      "+---+-------+-------------------------+\n",
      "|1  |Alice  |alice.johnson@example.com|\n",
      "|3  |Charlie|charlie.brown@example.com|\n",
      "|5  |Emma   |emma.davis@example.com   |\n",
      "+---+-------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify Users Who Added to Cart but Didn't Purchase\n",
    "# Business Need: Find users who have added a product to the cart but never completed a purchase.\n",
    "# Insight: Helps in retargeting users who abandoned their carts.\n",
    "\n",
    "# The tables that can answer the above question are : users and userActivity\n",
    "# 1st Method\n",
    "\n",
    "output1 = spark.sql(\"\"\"\n",
    "select u.id, u.name, u.email\n",
    "from users u\n",
    "join\n",
    "    (select distinct ua1.user_id\n",
    "from userActivity ua1\n",
    "join userActivity ua2\n",
    "where\n",
    "ua1.user_id = ua2.user_id\n",
    "and ua1.product_id = ua2.product_id\n",
    "and ua1.activity_type = 'add_to_cart'\n",
    "and ua2.activity_type != 'purchase'\n",
    "    )temp\n",
    "on u.id = temp.user_id\"\"\")\n",
    "\n",
    "output1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bc6e28d-4a5e-4e2f-8d13-40a4f22157d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------------+\n",
      "|id |name   |email                    |\n",
      "+---+-------+-------------------------+\n",
      "|1  |Alice  |alice.johnson@example.com|\n",
      "|3  |Charlie|charlie.brown@example.com|\n",
      "|5  |Emma   |emma.davis@example.com   |\n",
      "+---+-------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2nd Method\n",
    "output2 = spark.sql(\"\"\"select u.id, u.name, u.email\n",
    "from users u\n",
    "join(\n",
    "SELECT DISTINCT ua.user_id\n",
    "FROM userActivity ua\n",
    "WHERE ua.activity_type = 'add_to_cart'\n",
    "AND NOT EXISTS (\n",
    "    SELECT 1 FROM userActivity ua2\n",
    "    WHERE ua2.user_id = ua.user_id\n",
    "    AND ua2.product_id = ua.product_id\n",
    "    AND ua2.activity_type = 'purchase'\n",
    "))temp\n",
    "on u.id = temp.user_id\"\"\")\n",
    "\n",
    "output2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a46956ec-7cf5-4f60-b2d1-5fb6ac6ab8a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------------------------------+------+\n",
      "|id |name      |description                        |counts|\n",
      "+---+----------+-----------------------------------+------+\n",
      "|102|Smartphone|Flagship 5G smartphone             |4     |\n",
      "|101|Laptop    |15-inch gaming laptop              |2     |\n",
      "|103|Headphones|Noise-canceling wireless headphones|2     |\n",
      "|106|Monitor   |27-inch 4K UHD display             |1     |\n",
      "|104|Smartwatch|Waterproof fitness tracker         |1     |\n",
      "+---+----------+-----------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Find the Most Popular Products Based on User Engagement\n",
    "# Business Need: Determine which products are the most viewed or added to carts before purchase.\n",
    "# Insight: Helps in identifying high-engagement products for promotions.\n",
    "\n",
    "# The tables that can answer the above question are : products and userActivity\n",
    "# 1st Method (Using Subquery and count window function)\n",
    "\n",
    "output3 = spark.sql(\"\"\"\n",
    "select p.id, p.name, p.description, temp.cnt as counts\n",
    "from products p\n",
    "join\n",
    "( select distinct ua.product_id, count(ua.product_id) over (partition by ua.product_id) as cnt\n",
    "from userActivity ua)temp\n",
    "on p.id = temp.product_id\n",
    "order by counts desc\n",
    "limit 5\"\"\")\n",
    "\n",
    "output3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b45ea06e-d05e-4c81-8dc5-57bd6c10e7b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+----------+---------------+\n",
      "|id |name      |total_views|total_adds|total_purchases|\n",
      "+---+----------+-----------+----------+---------------+\n",
      "|102|Smartphone|2          |0         |2              |\n",
      "|101|Laptop    |1          |1         |0              |\n",
      "|103|Headphones|1          |1         |0              |\n",
      "|104|Smartwatch|0          |1         |0              |\n",
      "|106|Monitor   |1          |0         |0              |\n",
      "+---+----------+-----------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2nd Method (Using count along with Case statement to bifurcate the user_activity)\n",
    "output4 = spark.sql(\"\"\"SELECT p.id, p.name,\n",
    "       COUNT(CASE WHEN ua.activity_type = 'view' THEN 1 END) AS total_views,\n",
    "       COUNT(CASE WHEN ua.activity_type = 'add_to_cart' THEN 1 END) AS total_adds,\n",
    "       COUNT(CASE WHEN ua.activity_type = 'purchase' THEN 1 END) AS total_purchases\n",
    "FROM products p\n",
    "JOIN userActivity ua ON p.id = ua.product_id\n",
    "GROUP BY p.id, p.name\n",
    "ORDER BY total_purchases DESC, total_adds DESC, total_views DESC\n",
    "LIMIT 5\"\"\")\n",
    "\n",
    "output4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "661a318c-3a16-4b61-8bd1-115565e14e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+----------+---------------+\n",
      "|id |name      |total_views|total_adds|total_purchases|\n",
      "+---+----------+-----------+----------+---------------+\n",
      "|102|Smartphone|2          |0         |2              |\n",
      "|101|Laptop    |1          |1         |0              |\n",
      "|103|Headphones|1          |1         |0              |\n",
      "|104|Smartwatch|0          |1         |0              |\n",
      "|106|Monitor   |1          |0         |0              |\n",
      "+---+----------+-----------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3rd Method (Using Sum-IF statement to bifurcate the user_activity)\n",
    "output5 = spark.sql(\"\"\"SELECT p.id, p.name,\n",
    "       SUM(IF(ua.activity_type = 'view', 1, 0)) AS total_views,\n",
    "       SUM(IF(ua.activity_type = 'add_to_cart', 1, 0)) AS total_adds,\n",
    "       SUM(IF(ua.activity_type = 'purchase', 1, 0)) AS total_purchases\n",
    "FROM products p\n",
    "JOIN userActivity ua ON p.id = ua.product_id\n",
    "GROUP BY p.id, p.name\n",
    "ORDER BY total_purchases DESC, total_adds DESC, total_views DESC\n",
    "LIMIT 5\"\"\")\n",
    "\n",
    "output5.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f0a0178-acb1-41d8-bca7-7f7f67329da2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------------+------------+\n",
      "|id |name   |email                     |lifetime_val|\n",
      "+---+-------+--------------------------+------------+\n",
      "|2  |Bob    |bob.smith@example.com     |1999.00     |\n",
      "|1  |Alice  |alice.johnson@example.com |1250.00     |\n",
      "|6  |Frank  |frank.miller@example.com  |999.00      |\n",
      "|4  |David  |david.williams@example.com|450.00      |\n",
      "|7  |Grace  |grace.wilson@example.com  |350.00      |\n",
      "|3  |Charlie|charlie.brown@example.com |250.00      |\n",
      "|5  |Emma   |emma.davis@example.com    |180.00      |\n",
      "|8  |Hannah |hannah.moore@example.com  |120.00      |\n",
      "|10 |Jack   |jack.anderson@example.com |100.00      |\n",
      "|9  |Ian    |ian.taylor@example.com    |80.00       |\n",
      "+---+-------+--------------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate Customer Lifetime Value (CLV)\n",
    "# Business Need: Find the total amount each user has spent.\n",
    "# Insight: Helps in segmenting high-value customers for exclusive deals.\n",
    "\n",
    "# The tables that can answer the above question are : users and orders\n",
    "\n",
    "output6 = spark.sql(\"\"\"select u.id, u.name, u.email, temp.lifetime_val\n",
    "from users u\n",
    "join\n",
    "    (select o.user_id, sum(total_amt) as lifetime_val\n",
    "from orders o\n",
    "group by o.user_id)temp\n",
    "on u.id = temp.user_id\n",
    "order by temp.lifetime_val desc\"\"\")\n",
    "\n",
    "output6.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Importing MySQL Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
